---
title: '魔改 Grafana 我学到的事'
published: true
date: '2017-03-12 21:41'
taxonomy:
    category:
        - blog
        - Work
    tag:
        - Docker
        - Golang
header_image_file: 'https://ws1.sinaimg.cn/mw1024/e724cbefgy1fdcdnvrddtj218g0nm1kx'
hljs: true
comments: true
---

我，一个 Java 的忠粉，前些日子也不得不开始用 Golang 写一些东西，原因其实很简单，语言也好信仰也好，都敌不过一个基本实现需求的能够为我节省大量代码的开源软件。

一年之前第一次值班，被各种问题弄得焦头烂额，当时就想着要是有个系统，能把生产系统中正在发生的各种问题以告警的方式给出来，同时附带解决方案该多好。当时也是初生牛犊不怕虎，值班日报里随即把基于日志采集实现业务监控、可视化的方案说了一通，复用阿里云的各种基础设施，也许只要数天就能搭建一套完备的日志采集、存储、分析、可视化、告警体系。

===

于是实现这个方案就成了我的工作，但是有一个约束：为了实现依赖最小化，我必须使用团队内部提供的基础设施来实现，不能使用中间件那套虽然看起来完善但是底下不知道水多深的技术栈。

吭哧吭哧搞了一的多月，整合业界常见的大数据三板斧 Storm 和 Kafka，加上团队提供的 [HybridDB][1] 数仓，还有在生产代码里加上埋点，我也算是造了一套日志采集、存储、分析的轮子。但是这套系统我一直不好意思拿出去给同事们用，因为它太难用了。难用不难用和我用什么后端技术完全没关系，只和我用什么用户界面有关系。之前我在菜鸟的时候，基于 ODPS（现在叫 [MaxCompute][2]）做的日志查询和分析，虽然能实现很多功能，比如准实时生产日志查询、性能剖析、强弱依赖分析等等，但是因为获取这些信息的时候需要写 SQL，结果就是除了我之外没几个同事在用。

没有一个靠谱的用户界面一直是我这套日志系统的致命硬伤，但是业界之前似乎没有什么好的能够直接基于关系数据库做可视化的开源系统。直到后来我才知道 Airbnb 开源了一个 superset。其实我看一直都想要用上 Grafana，一个是因为它酷炫的界面，另一个则是它在 4.x 版本里新出的 Alert 功能。一旦能够用上 Grafana，那么我的日志系统就有了一个超级靠谱的可视化用户界面，和一个勉强可用的监控告警，整个功能就齐全了。

也许还真是我运气不错，让我在 Github 里找到一个数据源插件，这个插件能够让 Grafana 使用 MySQL 协议或者 PostgreSQL 协议从关系数据库中获取数据并展示出来，实现类似于 Influxdb 的效果。美中不足的是，这个插件不支持 Alert 功能，因为这个插件是在 3.x 下开发的，而 Alert 在 4.x 才有，也只有 Grafana 官方维护的数据源才同步支持了 Alert。

魔改开源软件，我也算是一把好手了。Grafana 经过本绅士的魔改之后，不仅支持 SQL 数据源，还给 SQL 数据源加上了 Alert 功能；不仅可以在 Alert 时发邮件，还能往钉钉群推消息；不仅能推消息，还能提醒指定的人，还能根据变量渲染告警消息；存放告警指标截图的图床，除了原生支持的 S3 和 WebDAV，我还给加上了阿里云 OSS；之前只能明文放在配置文件里的数据库和密码，被我加密存起来了……

经过我魔改的Grafana，不仅在我所在的小团队里迅速被几个业务采用，还以软件包的形式给输出其他团队，其中的杀手级特性，当属钉钉推送，这也算是我意料之中的~

托 Grafana 的福，我写了一星期的 Golang，也算是又多了一门上过生产环境的语言。除了 Golang，我还发现一些有趣的软件工程技巧和常见的设计缺陷，一并记录下来。

1. Golang 的错误处理真是麻烦得不行
   
   ```
   if out, err := json.Marshal(); err != nil {
       // handle error
   } else {
       // real code
   }
   ```
   
   Golang 迫使用户在几乎所有函数返回之后，立刻处理函数返回值中的错误信息。但是在我写过的有用的代码中，几乎所有深层代码，是没有能力去处理各种异常/错误的，只能把异常/错误原封不动交给上一层调用。在函数返回值中返回错误信息，不仅使得错误处理和业务逻辑耦合在一起，还让我们喜闻乐见的连续调用变的不可能。

   ```
   // other languages
   return f(g(x))
   // Golang
   if gg, err := g(x): err != nil {
       return nil, err
   } else {
       if ff, err := f(gg); err != nil {
          return nil, err
       } else {
           return ff, nil
       }
   }
   ```

   真是简洁优雅呢~

2. 在系统启动过程中自动执行数据库变更

   Grafana 有一套 Migration 代码，用来在系统启动并连接到数据库之后，自动执行诸如创建表结构、表结构升级之类的操作。也许是出于便于集中权限管理的原因，我从没在工作中见到有一个系统是这么做的，我们都需要在系统进入 stage 环境之前就把 DDL 提交到数据库管理平台上，由 DBA 审核之后才能在业务低峰期执行。也许这也和我一直以来的工作都是维护 SaaS  提供服务而不是输出软件有关系，但是这种做法在需要输出软件的时候真的很方便用户，无论是部署还是使用都很方便。

3. Docker build 阶段使用代理来加速网络

   在为开源软件做 Docker 镜像的时候，经常在 build 阶段耗费大量时间，就算把明面上需要下载的资源弄到了本地，还是会在一些看不到的地方访问一些不存在的网站，比如 npm install 的时候，即使把仓库指向了墙内镜像，也还是招架不住某些软件包在 install.js 里去 Github 下东西，然后 Github 的资源又是托管在 S3 上的，除非在打包的时候开个 VPN 全局代理，否则 build 过程卡个半个多一个小时没结果是常有的事情。

   幸好 Docker build 有一个 `--build-arg` 参数，可以在 build 阶段设置一些环境变量，比如 `docker build --build-arg HTTPS_PROXY=127.0.0.1:8888 nobody/awesome-image .`，就可以在构建镜像的时候指定一个 https 协议代理。需要注意的是 mac OS 上的 Docker 是运行在一个虚拟机里的，127.0.0.1 指向的是虚拟机而不是宿主机，所以在 mac OS 上使用这个黑科技的时候，要把 IP 改成宿主机的 IP。

4. 超时控制

   超时（Timeout）是每个在线系统需要在意的事情，只要是可以遇见到会有较长耗时的阻塞调用，就得考虑如果在可接受的时间内无法拿到结果该如何处理；如果一次请求内有多个可能阻塞的调用， 还需要根据这些调用的重要程度和预期的请求耗时，安排合理的超时配置。Grafana 的 Alert 特性在这一点上做得比较糟糕。

   Alert 的大体流程分为查询指标、判断条件、渲染图片、推送通知四个步骤，整体的超时为 30s。查询指标是最基本的步骤，如果这步超时基本 Alert 就废了；判断条件是纯内存计算，不会超时；推送通知也很重要，该推送的告警信息推不出来，这个功能也就废了；唯一一个锦上添花的功能就是渲染图片。Grafana 发现监控指标异常后，使用 PhantomJS 来打开监控指标所在页面并将页面渲染成 PNG 格式的图片，然后尝试调用可用的 image uploader 将图片上传至图床，供推送通知使用。
   
   然而渲染图片这步经常出问题，PhantomJS 加载网页经常加载到一半就堵住了，成功渲染的几率大概只有一半。出乎我意料的是，Grafana 源码中为渲染设置的超时时间也是 30s，直接就把 Alert 的超时传过去了，于是一旦渲染图片超时，告警信息也就推不出来了，巨坑。
   
5. 魔改开源代码的时候要给日后合并上游更新留下方便

   很多时候我们在工作中对开源项目的魔改，是很难贡献回社区的，一个原因是这种魔改是一种特定语境下的解决方案，不是社区想要的通用解决方案，比如我之前写的让 pip 去 Nexus 仓库找包的 mpip，以及这次给 Grafana 整合 SQL 数据源、钉钉群推送之类的东西，都是如此；另一个原因是工作期间写下的代码，所有权其实是属于公司的，不走流程就直接拿到公司外面不仅不合适还要承担责任，走流程这种事情大多数时候吃力不讨好，不是 AliSQL 或者 Tengine 这种重量级的项目就不要浪费精力去开源了。
   
   上游的代码变更总是让我们这些悄悄维护一个私有分支的人又爱又恨，爱的是有许多厉害的新特性可以给我们魔改的系统拿来撑门面，恨的是我们魔改得太厉害合并一次上游总是要花上一两天的功夫。可以预见到 Grafana 还处在一个快速迭代的时期，我虽然从 4.1.2 这个最新的稳定版本开始分叉，但是 4.2.0 已经在开发中了，不知道过几个版本会有什么吸引我的东西出来，但是肯定会有。于是我想到一个可行的分支策略：
   
   1. 确保 master 分支仅从 github/master 上拉变更
   2. 新增内部稳定分支 mod/master 做为主分支，最开始的时候从 master 的某个 release tag 分叉得到
   3. 锁定 master 和 mod/master，功能分支只允许 merge request 至 mod/master
   4. 软件包版本号为分为两段，第一段为上游版本号，第二段为魔改版本号
   5. 合并上游时将 github/master 同步到 master，然后从 master 上拉新分支 merge mod/master，解决冲突，然后再 merge 回 mod/master。
   6. 合并完上游后，魔改版本号不变，上游版本号用新版本号。

   接下来一段时间应该还会有一些魔改开源的工作，可以实践一下这个策略~
   
   除了分支策略，限定代码的魔改范围也很重要，尽可能把魔改代码和上游代码隔离，至少在目录级别隔离，尽在必要的少数几个入口，在上游代码中插入对魔改代码的引用或者调用，这样也能尽可能减少代码冲突的机会。

玩得开心~

[1]: https://www.aliyun.com/product/gpdb
[2]: https://www.aliyun.com/product/odps


