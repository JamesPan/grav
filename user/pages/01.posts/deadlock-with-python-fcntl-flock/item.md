---
title: 一不小心被文件锁坑了然后就死锁了
date: '2017-03-26 00:08'
taxonomy:
    category:
        - blog
        - Study
    tag:
        - Linux
        - Python
comments: true
---

前几天同事来找我看一个问题，说是一个 Python 进程完全堵住了。从日志来看确实是堵住了，卡在了一个奇怪的地方：尝试获取文件锁。比较悲催的是这段堵住的代码是我写的，简单地包装了一下领域相关的 Cgroups 操作和一些目录、权限的创建和回收。之前这份差事在我眼中属于「无聊的日常」。

工作并不总是充满挑战和乐趣，正因为大部分工作都是无聊的日常和琐碎的协作，有时候还有无奈的填坑和妥协的背锅，挑战和乐趣才显得难能可贵。

===

文件锁我用的是 `fcntl.flock`，通过 strace 命令查看进程正在进行的系统调用，确实能看到进程阻塞在 `flock` 函数上，`cat /proc/locks` 能看到目标进程除了正在持有一个 FLOCK，还有另外两个尝试获取锁的操作，只不过很不幸地被正在持有的锁阻塞了。

文件锁这种东西就是比较坑，没有什么方法能够从外部让进程主动释放，除非杀死进程，或者换一个文件。但是出乎我意料的是，即便我把目标进程重启了，它还是会阻塞在获取锁的操作上，从 `/proc/locks` 来看，锁确实没有被释放，而持有锁的进程，则是一个早已不存在的进程。

灵异事件！不存在的进程居然还能持有文件锁！

一番探寻之后，用 `lsof` 发现了真相：持有文件锁的，不是所谓的不存在的进程，而是这个不存在的进程的子进程。在我贫瘠的知识中，只知道大多数时候 fork 出来的子进程会持有父进程持有的文件描述符（aka fd），但是文件锁这种东西也会被继承？

上网查询了相关资料，我才发现有一种坑爹的文件锁，是真的有可能伴随着 fd 一起被子进程继承的，非常不幸，这种文件锁恰好就是我用的那个，`fcntl.flock`。

既然知道了原因，解决起来就容易了，要么把文件锁换成 `fcntl.lockf`，要么在用 `subprocess.Popen` 创建子进程的时候，带上参数 `close_fds=True`，让创建出来的子进程把除了 stdin，stdout，stderr 之外的 fd 全关掉，别从父进程带一大堆有的没的文件过来。

没想到这原本无聊的日常也能让我学到新知识。现实中我们总是不得不去用一些一知半解的技术，基本上都是看文档怎么用，别人怎么用，自己也就跟着怎么用，测试测试没问题就上，出了问题再排查，查不出来就弃坑换别的技术，查出来就修。

我能怎么办呀？我也很绝望啊。

相关资料：  
[File locking in Linux](https://gavv.github.io/blog/file-locks/)  
[Linux的进程间通信-文件和文件锁](http://liwei.life/2016/07/31/file_and_filelock/)  

